text = '''Humpty Dumpty sat on a wall
Humpty Dumpty had a great fall
all the king's horses and all the king's men
couldn't put Humpty together again'''
import math
import numpy as np

def main(text):
    # tasks your code should perform:

    # 1. split the text into words, and get a list of unique words that appear in it
    # a short one-liner to separate the text into sentences (with words lower-cased to make words equal 
    # despite casing) can be done with 
    
    docs = [line.lower().split() for line in text.split('\n')]
    
    # getting the list of unique words in the text
    
    vocabulary = (list(set(text.lower().split())))
    
    
    # 2. go over each unique word and calculate its term frequency, and its document frequency
    
    tf = {}
    df = {}
    N = len(docs)
    
    for word in vocabulary:
         
        tf[word] = [line.count(word)/len(line) for line in docs]
        df[word] = sum([word in doc for doc in docs])/N
        
    
    # 3. after you have your term frequencies and document frequencies, go over each line in the text and 
    # calculate its TF-IDF representation, which will be a vector
    
    tfidf = []
    for line_index,line in enumerate(docs):
        tfidf_line = []
        for word in vocabulary:
            tfidf_line.append(tf[word][line_index]*(math.log(1/df[word],10)))
        
        tfidf.append(tfidf_line)
        
        
    # 4. after you have calculated the TF-IDF representations for each line in the text, you need to
    # calculate the distances between each line to find which are the closest.
    
    N1 = len(tfidf)
    dist = np.empty((N1, N1), dtype=np.float)
    
    for i in tfidf:
        for j in tfidf:
            d = 0
            for item_i, item_j in zip(i,j):
                d += abs(item_i - item_j)
            if d == 0:
                d = np.inf
            dist[tfidf.index(i),tfidf.index(j)] = d   
    
    print(np.unravel_index(np.argmin(dist), dist.shape))
   
main(text)
